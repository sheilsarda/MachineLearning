{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "missing_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh-HecfbzuOU"
      },
      "source": [
        "# **CIS 520: Machine Learning, Fall 2020**\n",
        "# **Week 9, Worksheet 2**\n",
        "## **Missing Data** \n",
        "\n",
        "\n",
        "- **Content Creator:** Kenneth Shinn\n",
        "- **Content Reviewers:** Hanwen Zhang, Mohit Kumaraian\n",
        "<!-- - **Reference:**  -->\n",
        "<!-- <ul>\n",
        "<li>https://towardsdatascience.com/k-means-clustering-with-scikit-learn-6b47a369a83c\n",
        "<li>https://medium.com/swlh/gaussian-mixture-models-gmm-1327a2a62a\n",
        "</ul> -->\n",
        "\n",
        "\n",
        "This worksheet will work through an example of missing data imputation using both means and regression. Here, we are going to compare the performance of those two missing data imputation techniques from lecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Cvrn9I0Lqu"
      },
      "source": [
        "# **Missing Data**\n",
        "\n",
        "We will split up a data set into testing and training data. The training data will have data elements randomly dropped, and we will use the two strategies to impute the missing data. NOTE: this worksheet will have data missing at random. Then, we will train regression models on each of the imputed training sets, and see how they perform with the held out testing set!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZEzSotV1a_b"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from random import random\n",
        "from random import seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwmz-i3e51PH"
      },
      "source": [
        "Let's create a dataset using sklearn's make_regression function. This function randomly generates a data set for a regression problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1iUb3yb50o-"
      },
      "source": [
        "X, y = make_regression(n_samples = 100000, n_features = 2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "X_train_missing = X_train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6rPcazV7llT"
      },
      "source": [
        "Now, let's randomly drop values from the X_train data set. These missing values will be replaced with np.nan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVkHm0oS6dqN"
      },
      "source": [
        "seed(1)\n",
        "for i in range(len(X_train_missing)):\n",
        "    if random() < .3:\n",
        "        if random() < .5:\n",
        "            X_train_missing[i][0] = np.nan\n",
        "        else:\n",
        "            X_train_missing[i][1] = np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouFZG25Z844I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f01c622f-fdfb-4fc3-cf04-0bd28a5784fe"
      },
      "source": [
        "# make sure everything looks good!\n",
        "\n",
        "print(X_train_missing)\n",
        "print(len(X_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.48293426         nan]\n",
            " [-0.35371807  1.54279003]\n",
            " [        nan  1.35282604]\n",
            " ...\n",
            " [ 0.55075279  1.2841265 ]\n",
            " [-0.53599387         nan]\n",
            " [-0.06317035         nan]]\n",
            "70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LVtSuMM9rxK"
      },
      "source": [
        "**Simple Mean Based Imputation**\n",
        "\n",
        "Let's perform a mean based imputation on the dataset with missing values. Remember that a mean based imputation uses the mean of all non-missing values in the column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVb22RP9J2I"
      },
      "source": [
        "mean_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X_train_mean_imp = mean_imp.fit_transform(X_train_missing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdFktthy_X01"
      },
      "source": [
        "**Regression Based Imputation**\n",
        "\n",
        "Here, we will now do a regression based imputation on the dataset with missing values. Remember that a regression based imputation uses the other columns of non-missing data to predict the missing data of a given column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYuRpsGZ_W6_"
      },
      "source": [
        "reg_imp = IterativeImputer(missing_values=np.nan)\n",
        "X_train_reg_imp = reg_imp.fit_transform(X_train_missing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9RdiNKYApnZ"
      },
      "source": [
        "**Training and Testing on the Imputed Datasets**\n",
        "\n",
        "Now, let's train OLS regression on each of the imputed data sets and compare their testing MSE. \n",
        "\n",
        "Which method do you expect to have the lower test MSE? Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inMdjglMA3S1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bdeb8166-dad0-40b5-e36f-d529e91dbd91"
      },
      "source": [
        "# training on mean imputed data\n",
        "mean_imp_lm = LinearRegression().fit(X_train_mean_imp, y_train)\n",
        "y_pred_mean_imp = mean_imp_lm.predict(X_test)\n",
        "mse_mean_imp = mean_squared_error(y_test, y_pred_mean_imp)\n",
        "\n",
        "print(\"Mean Imputed Data MSE: \" + str(mse_mean_imp))\n",
        "\n",
        "# training on regression imputed data\n",
        "reg_imp_lm = LinearRegression().fit(X_train_reg_imp, y_train)\n",
        "y_pred_reg_imp = reg_imp_lm.predict(X_test)\n",
        "mse_reg_imp = mean_squared_error(y_test, y_pred_reg_imp)\n",
        "\n",
        "print(\"Regression Imputed Data MSE: \" + str(mse_reg_imp))\n",
        "\n",
        "# training on full X_train data\n",
        "lm = LinearRegression().fit(X_train, y_train)\n",
        "y_pred = lm.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"True X_train MSE: \" + str(mse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Imputed Data MSE: 0.011240654108897059\n",
            "Regression Imputed Data MSE: 0.011989879045445921\n",
            "True X_train MSE: 2.9998313648798715e-28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zvqZLuhFVim"
      },
      "source": [
        "**Observations and Followup Questions**\n",
        "\n",
        "Which imputation technique produced the lower MSE? Why do you think that this is the case? Is this what you expected?\n",
        "\n",
        "Think about why regression imputation didn't work significantly better here despite having \"more information\"? (hint: the x variables of the data generating model are indepedent) \n",
        "\n",
        "How might these MSE results change if there was a slight correlation between the x variables?\n",
        "\n",
        "Which imputation technique do you think would work better in the real world? Why?"
      ]
    }
  ]
}