{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "232HpCl3DubJ"
      },
      "source": [
        "# **CIS 520: Machine Learning, Fall 2020**\n",
        "# **Week 14, Worksheet 2**\n",
        "## **Auto Machine Learning**\n",
        "\n",
        "\n",
        "- **Content Creator:** Shaozhe Lyu\n",
        "- **Content Checkers:** Michael Zhou, Siyun Hu\n",
        "- **Acknowledgements:** This notebook contains an excerpt from the [auto-sklearn](https://automl.github.io/auto-sklearn/master/) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo0rwiaX9lIL"
      },
      "source": [
        "\n",
        "Auto-sklearn frees a machine learning user from algorithm selection and hyperparameter tuning. It leverages recent advantages in Bayesian optimization, meta-learning and ensemble construction. Learn more about the technology behind auto-sklearn by reading the paper published at [NIPS 2015](https://proceedings.neurips.cc/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf) ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBm8Boyzhdv3"
      },
      "source": [
        "We will start by installing the packages swig and auto-sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWwv4Qk1e2u8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8862f3-3f5d-4bd9-8c50-611c1232e69f"
      },
      "source": [
        "!sudo apt-get install swig -y\n",
        "!pip install Cython numpy\n",
        "!pip install pipelineprofiler\n",
        "!pip install auto-sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 1s (1,258 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Collecting pipelineprofiler\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/1a/044138411dfe8ed93d12e983675cb2057602406c54394c17a25be6c21914/pipelineprofiler-0.1.15-py3-none-any.whl (879kB)\n",
            "\u001b[K     |████████████████████████████████| 880kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pipelineprofiler) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pipelineprofiler) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pipelineprofiler) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from pipelineprofiler) (2.8.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from pipelineprofiler) (5.3.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pipelineprofiler) (2.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pipelineprofiler) (0.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->pipelineprofiler) (1.15.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (4.7.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (5.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (2.11.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (5.0.8)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (4.10.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (0.9.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (4.3.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook->pipelineprofiler) (5.3.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pipelineprofiler) (4.4.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->pipelineprofiler) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->pipelineprofiler) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->pipelineprofiler) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->pipelineprofiler) (0.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->pipelineprofiler) (2.6.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->pipelineprofiler) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->pipelineprofiler) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->pipelineprofiler) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->pipelineprofiler) (2.6.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->pipelineprofiler) (5.5.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->pipelineprofiler) (0.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.0->notebook->pipelineprofiler) (20.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->pipelineprofiler) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->pipelineprofiler) (20.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (50.3.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (1.0.18)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook->pipelineprofiler) (2.4.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (0.2.5)\n",
            "Installing collected packages: pipelineprofiler\n",
            "Successfully installed pipelineprofiler-0.1.15\n",
            "Collecting auto-sklearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/09/e2311163385861101eb95e765adb74b266a4c1b309b84e3346f043e5f438/auto-sklearn-0.11.1.tar.gz (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn<0.23,>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.12.0)\n",
            "Collecting distributed>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/38/d9f0e31c15de18cb124d1ed33cf9c99c84f05f251ff6767e7573c217725b/distributed-2.30.1-py3-none-any.whl (656kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 39.9MB/s \n",
            "\u001b[?25hCollecting lockfile\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.1.4)\n",
            "Collecting liac-arff\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/43/73944aa5ad2b3185c0f0ba0ee6f73277f2eb51782ca6ccf3e6793caf209a/liac-arff-2.5.0.tar.gz\n",
            "Collecting ConfigSpace<0.5,>=0.4.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/f9/685e3cb6e2a87e4989b83950dfbe8cecc49fd158f4ff3d1368dc62014e8d/ConfigSpace-0.4.16.tar.gz (964kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 36.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynisher>=0.6.1\n",
            "  Downloading https://files.pythonhosted.org/packages/be/35/b8dc446bee0358f59e4abdc781004b80c7d3b9eb9bc3564116c1bfd47e5f/pynisher-0.6.3.tar.gz\n",
            "Collecting pyrfr<0.9,>=0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/0f/4d7e42a9dfef3a1898e03cffa8f1cfcd1f96507d718808b2db584c6f8401/pyrfr-0.8.0.tar.gz (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 33.8MB/s \n",
            "\u001b[?25hCollecting smac<0.14,>=0.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/f2/8ea040eaa2253a3606472b08d9c2a23be1a177c0c19e236a2b3222c0fd78/smac-0.13.1.tar.gz (258kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 32.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->auto-sklearn) (1.0.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->auto-sklearn) (5.4.8)\n",
            "Collecting contextvars; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->auto-sklearn) (5.1.1)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->auto-sklearn) (2.3.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->auto-sklearn) (0.11.1)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->auto-sklearn) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.21)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (2.4.7)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.6.1->auto-sklearn) (0.16)\n",
            "Collecting lazy_import\n",
            "  Downloading https://files.pythonhosted.org/packages/44/2e/5378f9b9cbc893826c2ecb022646c97ece9efbaad351adf89425fff33990/lazy_import-0.2.2.tar.gz\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: heapdict in /usr/local/lib/python3.6/dist-packages (from zict>=0.1.3->distributed>=2.2.0->auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
            "Building wheels for collected packages: ConfigSpace\n",
            "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.16-cp36-cp36m-linux_x86_64.whl size=2881518 sha256=1bb27eb41c24e7701399d7d0be302fb33898fd6b287fd4f7930d3ad79cb4cf11\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/13/2f/a0ae8e1081410d394133980a2ccd1c5524ed4f0c83ba9a61a7\n",
            "Successfully built ConfigSpace\n",
            "Building wheels for collected packages: auto-sklearn, liac-arff, pynisher, pyrfr, smac, contextvars, lazy-import\n",
            "  Building wheel for auto-sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.11.1-cp36-none-any.whl size=4086027 sha256=e0638d13709df5ee68f5a992a7f365c89f67e352c6cea43fabb49e21999b00d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/09/38/251380c672ba9bdb3526c18a87df0bd8aed33dadb7afe645e8\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-cp36-none-any.whl size=11734 sha256=2e05cf3b1335e632588638728690651813a0a9e12b28f84eb19d82be4ad58b4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/8d/b4/8bfce5beea9a3496cc15b24961876adb7b6e2912ff09164179\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.3-cp36-none-any.whl size=4798 sha256=c7e2d2397caf307143da80180a3a00c1bdcfa462e86bad792f393b54d58efcd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/d8/f2/2c835c2e48198621abb9f79f7d5d491b85f8902e4513c8eb62\n",
            "  Building wheel for pyrfr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrfr: filename=pyrfr-0.8.0-cp36-cp36m-linux_x86_64.whl size=2540848 sha256=13f194e9fc4232212d84896ca542a27c9d51655f9f4a2b14a4b5ef44f8c56ab4\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1a/d2/b5aee388a492a01946143d3c976b2ca810af537480e1f16999\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smac: filename=smac-0.13.1-cp36-none-any.whl size=252174 sha256=53e297b0e8527c7b4558e32336dde88d60778566defe6199a7c631ae43be0662\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/a6/af/9ec3c1ff517759ad1aad6babcbcf047dd5078c8b08fa4e63cc\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=77e5b1cbb1b554904af5d5cf2c9c6aa36338298473a3a83314f4267756dd4ac0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "  Building wheel for lazy-import (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lazy-import: filename=lazy_import-0.2.2-py2.py3-none-any.whl size=16486 sha256=962556a30824cc37edc86ed593e7fc095136be633e47f4f324d7fb45b7286cf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/b0/b5/8c7e6810aee14bc4ed4a542ce56e744126263bf4f4825a9094\n",
            "Successfully built auto-sklearn liac-arff pynisher pyrfr smac contextvars lazy-import\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement cloudpickle==1.3, but you'll have cloudpickle 1.6.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: immutables, contextvars, cloudpickle, distributed, lockfile, liac-arff, ConfigSpace, pynisher, pyrfr, lazy-import, smac, auto-sklearn\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed ConfigSpace-0.4.16 auto-sklearn-0.11.1 cloudpickle-1.6.0 contextvars-2.4 distributed-2.30.1 immutables-0.14 lazy-import-0.2.2 liac-arff-2.5.0 lockfile-0.12.2 pynisher-0.6.3 pyrfr-0.8.0 smac-0.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UpxgQQmi6Fr",
        "outputId": "6c70e9a3-9235-4201-97e3-39f4f24b2437"
      },
      "source": [
        "!git clone https://github.com/automl/auto-sklearn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'auto-sklearn'...\n",
            "remote: Enumerating objects: 152, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 36673 (delta 75), reused 54 (delta 30), pack-reused 36521\u001b[K\n",
            "Receiving objects: 100% (36673/36673), 33.64 MiB | 10.15 MiB/s, done.\n",
            "Resolving deltas: 100% (29288/29288), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh9d6ITx8OPv"
      },
      "source": [
        "Next, we will create a new file \"requirements.txt\" and then copy the block below into the file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ0AAEOvMV6H"
      },
      "source": [
        "setuptools\n",
        "\n",
        "numpy>=1.9.0\n",
        "scipy>=0.14.1\n",
        "\n",
        "joblib\n",
        "scikit-learn>=0.22.0,<0.23\n",
        "\n",
        "dask\n",
        "distributed>=2.2.0\n",
        "lockfile\n",
        "pyyaml\n",
        "pandas>=1.0\n",
        "liac-arff\n",
        "\n",
        "ConfigSpace>=0.4.14,<0.5\n",
        "pynisher>=0.6.1\n",
        "pyrfr>=0.7,<0.9\n",
        "smac>=0.13.1,<0.14\n",
        "distributed>=2.2.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILo4D6a1McR3"
      },
      "source": [
        "Through \"requirements.txt\", we will install all necessary dependencies and their corresponding versions: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR9o1IulMbrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254eca3f-6589-45d1-a5c2-0fc7c74bed4f"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn<0.23,>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.22.2.post1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (2.12.0)\n",
            "Requirement already satisfied: distributed>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (2.30.1)\n",
            "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.12.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (3.13)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (1.1.4)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (2.5.0)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (0.4.16)\n",
            "Requirement already satisfied: pynisher>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (0.6.3)\n",
            "Requirement already satisfied: pyrfr<0.9,>=0.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (0.8.0)\n",
            "Requirement already satisfied: smac<0.14,>=0.13.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (0.13.1)\n",
            "Requirement already satisfied: contextvars; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (2.4)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (1.6.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (2.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (2.3.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (1.7.0)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (5.1.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (0.11.1)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (5.4.8)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.2.0->-r requirements.txt (line 10)) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0->-r requirements.txt (line 13)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0->-r requirements.txt (line 13)) (2.8.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.14->-r requirements.txt (line 16)) (0.29.21)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.14->-r requirements.txt (line 16)) (2.4.7)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.6.1->-r requirements.txt (line 17)) (0.16)\n",
            "Requirement already satisfied: lazy-import in /usr/local/lib/python3.6/dist-packages (from smac<0.14,>=0.13.1->-r requirements.txt (line 19)) (0.2.2)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars; python_version < \"3.7\"->distributed>=2.2.0->-r requirements.txt (line 10)) (0.14)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.6/dist-packages (from zict>=0.1.3->distributed>=2.2.0->-r requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->-r requirements.txt (line 13)) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHrrQHfAh8gW"
      },
      "source": [
        "After installing all the dependencies, select **Restart runtime** to change the version and then import the auto machine learning library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifxr1kFzfOoX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import PipelineProfiler\n",
        "import autosklearn.classification\n",
        "import sklearn.model_selection\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGpL9p7amExS"
      },
      "source": [
        "## 1. Auto-sklearn Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W_8x681Md7S"
      },
      "source": [
        "## Data Loading\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_e8WGZ0oALJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "1ce8121e-d622-46d1-be21-8d52ba01b044"
      },
      "source": [
        "X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    sklearn.model_selection.train_test_split(X, y, random_state=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9cef62f0c43e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_breast_cancer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sklearn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWdfBWUep5dl"
      },
      "source": [
        "## Building and Fit\n",
        "**time_left_for_this_task**, optional (default=3600):\n",
        "Time limit in seconds for the search of appropriate models. By increasing this value, auto-sklearn has a higher chance of finding better models.\n",
        "\n",
        "**per_run_time_limit**, optional (default=1/10 of time_left_for_this_task):\n",
        "Time limit for a single call to the machine learning model. Model fitting will be terminated if the machine learning algorithm runs over the time limit. Set this value high enough so that typical machine learning algorithms can be fit on the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA-HAqweoCw_",
        "outputId": "7ddce9da-c9e6-4da4-bfc7-124090f2b8ff"
      },
      "source": [
        "automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "    time_left_for_this_task=120,\n",
        "    per_run_time_limit=30,\n",
        "    tmp_folder='/tmp/autosklearn_classification_example_tmp',\n",
        "    output_folder='/tmp/autosklearn_classification_example_out',\n",
        ")\n",
        "automl.fit(X_train, y_train, dataset_name='breast_cancer')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoSklearnClassifier(dask_client=None,\n",
              "                      delete_output_folder_after_terminate=True,\n",
              "                      delete_tmp_folder_after_terminate=True,\n",
              "                      disable_evaluator_output=False, ensemble_nbest=50,\n",
              "                      ensemble_size=50, exclude_estimators=None,\n",
              "                      exclude_preprocessors=None, get_smac_object_callback=None,\n",
              "                      include_estimators=None, include_preprocessors=None,\n",
              "                      initial_configurations_via_metal...\n",
              "                      max_models_on_disc=50, memory_limit=3072,\n",
              "                      metadata_directory=None, metric=None, n_jobs=None,\n",
              "                      output_folder='/tmp/autosklearn_classification_example_out',\n",
              "                      per_run_time_limit=30, resampling_strategy='holdout',\n",
              "                      resampling_strategy_arguments=None, seed=1,\n",
              "                      smac_scenario_args=None, time_left_for_this_task=120,\n",
              "                      tmp_folder='/tmp/autosklearn_classification_example_tmp')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz3_AleBtGsH"
      },
      "source": [
        "Now we print the final ensemble constructed by auto-sklearn. From this part you can see which kinds of classifier are ensembled by auto-ML. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d0jBelqoEo0",
        "outputId": "a3b500d5-be32-4476-c1ca-d118d2f5d0ab"
      },
      "source": [
        "print(automl.show_models())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0.320000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'polynomial', 'classifier:gradient_boosting:early_stop': 'valid', 'classifier:gradient_boosting:l2_regularization': 8.495727973549814e-08, 'classifier:gradient_boosting:learning_rate': 0.10895774269386836, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 6, 'classifier:gradient_boosting:min_samples_leaf': 17, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.009766287299931831, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 917, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal', 'feature_preprocessor:polynomial:degree': 2, 'feature_preprocessor:polynomial:include_bias': 'False', 'feature_preprocessor:polynomial:interaction_only': 'False', 'classifier:gradient_boosting:n_iter_no_change': 16, 'classifier:gradient_boosting:validation_fraction': 0.018763788815745606},\n",
            "dataset_properties={\n",
            "  'task': 1,\n",
            "  'sparse': False,\n",
            "  'multilabel': False,\n",
            "  'multiclass': False,\n",
            "  'target_type': 'classification',\n",
            "  'signed': False})),\n",
            "(0.180000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01},\n",
            "dataset_properties={\n",
            "  'task': 1,\n",
            "  'sparse': False,\n",
            "  'multilabel': False,\n",
            "  'multiclass': False,\n",
            "  'target_type': 'classification',\n",
            "  'signed': False})),\n",
            "(0.160000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'liblinear_svc_preprocessor', 'classifier:random_forest:bootstrap': 'False', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.21772092350860472, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 14, 'classifier:random_forest:min_samples_split': 17, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0020488212891693275, 'feature_preprocessor:liblinear_svc_preprocessor:C': 33.74257606530722, 'feature_preprocessor:liblinear_svc_preprocessor:dual': 'False', 'feature_preprocessor:liblinear_svc_preprocessor:fit_intercept': 'True', 'feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling': 1, 'feature_preprocessor:liblinear_svc_preprocessor:loss': 'squared_hinge', 'feature_preprocessor:liblinear_svc_preprocessor:multi_class': 'ovr', 'feature_preprocessor:liblinear_svc_preprocessor:penalty': 'l1', 'feature_preprocessor:liblinear_svc_preprocessor:tol': 8.740452966205111e-05},\n",
            "dataset_properties={\n",
            "  'task': 1,\n",
            "  'sparse': False,\n",
            "  'multilabel': False,\n",
            "  'multiclass': False,\n",
            "  'target_type': 'classification',\n",
            "  'signed': False})),\n",
            "(0.120000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'passive_aggressive', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:__choice__': 'kernel_pca', 'classifier:passive_aggressive:C': 1.9137257120393358, 'classifier:passive_aggressive:average': 'True', 'classifier:passive_aggressive:fit_intercept': 'True', 'classifier:passive_aggressive:loss': 'hinge', 'classifier:passive_aggressive:tol': 0.00012613872674401282, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.013158489866755073, 'feature_preprocessor:kernel_pca:kernel': 'rbf', 'feature_preprocessor:kernel_pca:n_components': 651, 'feature_preprocessor:kernel_pca:gamma': 0.08989386584219308},\n",
            "dataset_properties={\n",
            "  'task': 1,\n",
            "  'sparse': False,\n",
            "  'multilabel': False,\n",
            "  'multiclass': False,\n",
            "  'target_type': 'classification',\n",
            "  'signed': False})),\n",
            "(0.100000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'qda', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:qda:reg_param': 0.563056219822946, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.32793677336996485},\n",
            "dataset_properties={\n",
            "  'task': 1,\n",
            "  'sparse': False,\n",
            "  'multilabel': False,\n",
            "  'multiclass': False,\n",
            "  'target_type': 'classification',\n",
            "  'signed': False})),\n",
            "(0.060000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'polynomial', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'entropy', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 10, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal', 'feature_preprocessor:polynomial:degree': 3, 'feature_preprocessor:polynomial:include_bias': 'True', 'feature_preprocessor:polynomial:interaction_only': 'True'},\n",
            "dataset_properties={\n",
            "  'task': 1,\n",
            "  'sparse': False,\n",
            "  'multilabel': False,\n",
            "  'multiclass': False,\n",
            "  'target_type': 'classification',\n",
            "  'signed': False})),\n",
            "(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'polynomial', 'classifier:gradient_boosting:early_stop': 'off', 'classifier:gradient_boosting:l2_regularization': 0.0006322356877253852, 'classifier:gradient_boosting:learning_rate': 0.02155479872417127, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 6, 'classifier:gradient_boosting:min_samples_leaf': 15, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'feature_preprocessor:polynomial:degree': 2, 'feature_preprocessor:polynomial:include_bias': 'True', 'feature_preprocessor:polynomial:interaction_only': 'False'},\n",
            "dataset_properties={\n",
            "  'task': 1,\n",
            "  'sparse': False,\n",
            "  'multilabel': False,\n",
            "  'multiclass': False,\n",
            "  'target_type': 'classification',\n",
            "  'signed': False})),\n",
            "(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'polynomial', 'classifier:gradient_boosting:early_stop': 'off', 'classifier:gradient_boosting:l2_regularization': 0.0001694678378411361, 'classifier:gradient_boosting:learning_rate': 0.02193023008887291, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 20, 'classifier:gradient_boosting:min_samples_leaf': 25, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'feature_preprocessor:polynomial:degree': 2, 'feature_preprocessor:polynomial:include_bias': 'False', 'feature_preprocessor:polynomial:interaction_only': 'False'},\n",
            "dataset_properties={\n",
            "  'task': 1,\n",
            "  'sparse': False,\n",
            "  'multilabel': False,\n",
            "  'multiclass': False,\n",
            "  'target_type': 'classification',\n",
            "  'signed': False})),\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSemr-aXtIW1"
      },
      "source": [
        "## Get the Score of the Final Ensemble\n",
        "\n",
        "If you want to have a higher score, you can increase the     **time_left_for_this_task** and     **per_run_time_limit** parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w0kYjcloozL",
        "outputId": "e328df33-f1ec-4ca6-db43-76ce80f6d237"
      },
      "source": [
        "predictions = automl.predict(X_test)\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9440559440559441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKcSQJU1xOJT"
      },
      "source": [
        "## Questions\n",
        "\n",
        "How well did the above method do compared to a standard random forest?\n",
        "\n",
        "What did it find was the most accurate model? (What contributed the most to the ensemble?)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds7Z7JVl1re3"
      },
      "source": [
        "AutoML can also be extended to use text description of problems to pick hyperparameters:\n",
        "* Use vector embeddings of dataset title, description and keywords\n",
        "* For each new dataset, find the most similar prior dataset and use its hyperparameters\n",
        "* The similarity metric is learned (supervised)\n"
      ]
    }
  ]
}