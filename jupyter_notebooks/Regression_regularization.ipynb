{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"},"colab":{"name":"Regression_regularization.ipynb","provenance":[{"file_id":"1uld-LixjnF1EvWacZdLV9YKYsZnKY4Pt","timestamp":1600100284433}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"p1FBCebKE1Ly","colab_type":"text"},"source":["# **CIS 520: Machine Learning, Fall 2020**\n","# **Week 3, Worksheet 2**\n","## **OLS/Ridge Regressions and Regularization**\n","\n","\n","- **Content Creators:** Lyle Ungar\n","- **Content Reviewers:** Michael Zhou"]},{"cell_type":"markdown","metadata":{"id":"MqKjec5GyAl9","colab_type":"text"},"source":["This short worksheet provides some simple exercises to see how OLS (MLE) and Ridge (MAP) regressions perform and what their bias and variance are. We will start by generating some data and fitting a OLS regression to this data."]},{"cell_type":"markdown","metadata":{"id":"iYSceYUUGJIk","colab_type":"text"},"source":["## Regression Setup"]},{"cell_type":"code","metadata":{"id":"iit7zoL0jAHw","colab_type":"code","colab":{}},"source":["from sklearn import linear_model\n","import numpy as np \n","x = np.random.random(10) \n","X = np.vstack([np.ones(len(x)), x]).T\n","y = 0.5* np.ones(10) + 2.0*x + np.random.normal(0,0.25,len(x))\n","ols = linear_model.LinearRegression()\n","ols.fit(X,y)\n","y_est = ols.predict(X)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wWcZSsZ8JoL4","colab_type":"text"},"source":["Next, we will plot our OLS regression along with our original data to better visualize how our regression fits to the data."]},{"cell_type":"code","metadata":{"id":"YHi7rCGjjAIT","colab_type":"code","colab":{}},"source":["#plot y and y_est vs x\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.plot(x, y_est, linewidth=2, color='blue')\n","plt.scatter(x, y, s=30, c='red', marker='+')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n_Hb611BKhLo","colab_type":"text"},"source":["We can also print our OLS regression predictions and compare them with the original dataset to get a sense of our regression's performance."]},{"cell_type":"code","metadata":{"id":"5RK-gEkDjAIa","colab_type":"code","colab":{}},"source":["print(x)\n","print(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Fet9-KajAIf","colab_type":"code","colab":{}},"source":["print(y)\n","print(y_est)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WRQcI9oPaxFn","colab_type":"text"},"source":["When it comes to regularization, here are some questions to consider:\n","\n","*   How will the amount of regularization change as a function of the number of observations?\n","*   How will the amount of regularization change as a function of the amount of noise in the data?\n"]},{"cell_type":"markdown","metadata":{"id":"07qwg43LHa8l","colab_type":"text"},"source":["## Exercises: Bias and Variance\n","\n","To better understand the bias and variance of OLS and Ridge regressions, work through the following exercises:\n","\n","1.   What is the bias of the estimates of the weights for OLS?\n","Generate the data 100 times, and see on average how they differ from their true values.\n","Do this (a) for OLS (b) using Ridge.\n","Should OLS and Ridge each be unbiased, negatively biased or positively biased?\n","2.   What is the variance of the estimates of the weights for OLS?\n","Generate the data 100 times, and see what the variance is of the weight estimates. Do this (a) for OLS (B) using Ridge. Which should have a higher variance?"]}]}